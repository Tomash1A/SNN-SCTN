{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0vN2UZv1H33A"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from collections import OrderedDict\n",
    "import snntorch as snn\n",
    "\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def gpu_mem_state():\n",
    "  # Print out the GPU memory usage\n",
    "  print(\"Memory allocated:\", torch.cuda.memory_allocated() / 1024**3, \"GB\")\n",
    "  print(\"Max memory allocated:\", torch.cuda.max_memory_allocated() / 1024**3, \"GB\")\n",
    "\n",
    "gpu_mem_state()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkYUK1DAYYGC",
    "outputId": "e96fe856-2791-4bae-eb82-060281891e88"
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.0 GB\n",
      "Max memory allocated: 0.0 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ResonatorSpikes:\n",
    "\n",
    "    def __init__(self, clk_freq, resonator_freq, spikes_path):\n",
    "        self.clk_freq = clk_freq\n",
    "        self.resonator_freq = resonator_freq\n",
    "        self.events = None\n",
    "        self._load_spikes(spikes_path)\n",
    "\n",
    "    def _load_spikes(self, spikes_path):\n",
    "        spikes_array = np.load(spikes_path)['spikes']\n",
    "        # if the file is already events based spikes\n",
    "        if np.max(spikes_array) > 1:\n",
    "            self.events = spikes_array\n",
    "        else:\n",
    "            self.events = np.where(spikes_array == 1)[0]\n",
    "\n",
    "    def spectrogram(self, window_ms):\n",
    "        window = int(self.clk_freq/1000 * window_ms)\n",
    "        N = self.events[-1] // window + 1\n",
    "        bins = np.zeros(N, dtype=int)\n",
    "        unique_indices, counts = np.unique(np.array(self.events) // window, return_counts=True)\n",
    "        bins[unique_indices] = counts\n",
    "        return bins\n",
    "\n",
    "\n",
    "class ChannelSpikes:\n",
    "\n",
    "    def __init__(self, base_folder, channel_name):\n",
    "        self.channel_name = channel_name\n",
    "        self.resonators_output = OrderedDict({})\n",
    "        self._load_resonators_output(base_folder)\n",
    "\n",
    "    def _load_resonators_output(self, base_folder):\n",
    "        channel_folder = base_folder / self.channel_name\n",
    "        for clk_freq in os.listdir(channel_folder):\n",
    "            clk_folder = channel_folder / clk_freq\n",
    "            for spikes in os.listdir(clk_folder):\n",
    "                resonator_freq = spikes[:-4]\n",
    "                self.resonators_output[resonator_freq] = ResonatorSpikes(int(clk_freq), float(resonator_freq), f'{clk_folder}/{spikes}')\n",
    "\n",
    "class SignalSpikes:\n",
    "\n",
    "    def __init__(self, signal_folder, label):\n",
    "        self.label = label\n",
    "        self.channels = OrderedDict({\n",
    "            channel: ChannelSpikes(signal_folder, channel)\n",
    "            for channel in os.listdir(signal_folder)\n",
    "        })\n",
    "\n",
    "\n",
    "class Trial:\n",
    "\n",
    "    def __init__(self, base_folder, trial):\n",
    "        self.trial = trial\n",
    "        self.base_folder = Path(f'{base_folder}/{trial}')\n",
    "\n",
    "    def load(self, minute):\n",
    "        # make sure it's in string format.\n",
    "        minute = str(minute)\n",
    "        for label in os.listdir(self.base_folder):\n",
    "            for m in os.listdir(self.base_folder / label):\n",
    "                if m == minute:\n",
    "                    return SignalSpikes(self.base_folder / label / m, label=label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EEGMentalSpikesDataset(Dataset):\n",
    "    def __init__(self, trials: List[Trial], minutes: List[int], time_sample_s: float, labels_mapper: Dict[str, int]):\n",
    "        self.time_sample_s = time_sample_s\n",
    "        self.labels_mapper = labels_mapper\n",
    "\n",
    "        self.samples_per_minute = int(60 / time_sample_s)\n",
    "        self.samples_per_trial = self.samples_per_minute * len(minutes)\n",
    "        self.length = len(trials) * self.samples_per_trial\n",
    "\n",
    "        self.loaded_spikes = {\n",
    "            f'{i}-{j}': trial.load(minute)\n",
    "            for i, trial in enumerate(trials)\n",
    "            for j, minute in enumerate(minutes)\n",
    "        }\n",
    "        # get resonators clk frequencies.\n",
    "        signal4example = next(iter(self.loaded_spikes.values()))\n",
    "        resonators = next(iter(signal4example.channels.values())).resonators_output\n",
    "\n",
    "        self.map_channel_to_id = {ch: i for i, ch in enumerate(signal4example.channels.keys())}\n",
    "        self.map_resonator_to_id = {f: i for i, f in enumerate(resonators.keys())}\n",
    "\n",
    "        clk_freq = list(set(map(lambda x: x.clk_freq, resonators.values())))\n",
    "        # least common multiplier of the resonators is network clk frequency\n",
    "        self.network_clk = np.lcm.reduce(clk_freq)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        num_rows = 40_000\n",
    "\n",
    "        trial_id = id // self.samples_per_trial\n",
    "        minute_id = (id % self.samples_per_trial) // self.samples_per_minute\n",
    "        sample = ((id % self.samples_per_trial) % self.samples_per_minute)\n",
    "\n",
    "        spike_signal = self.loaded_spikes[f'{trial_id}-{minute_id}']\n",
    "        label = self.labels_mapper[spike_signal.label]\n",
    "\n",
    "\n",
    "        # ordered dict to numpy array\n",
    "        # Determine the size of the resulting array\n",
    "        result = -np.ones((num_rows, 2), dtype=np.int64)\n",
    "        result_index = 0\n",
    "\n",
    "        for ch, channel_spikes in spike_signal.channels.items():\n",
    "            ch_id = self.map_channel_to_id[ch]\n",
    "            for f, resonator in channel_spikes.resonators_output.items():\n",
    "                resonator_id = self.map_resonator_to_id[f]\n",
    "                ticks_in_sample = int(self.time_sample_s * resonator.clk_freq)\n",
    "\n",
    "                ts_spikes = resonator.events\n",
    "                ts_spikes = ts_spikes[(ts_spikes >= (sample * ticks_in_sample)) & (ts_spikes < ((sample + 1) * ticks_in_sample))]\n",
    "\n",
    "                # make sure all spikes are aligned even though the spikes come from different clocks and different timestamp!\n",
    "                ts_spikes -= (sample * ticks_in_sample)\n",
    "                ts_spikes = ts_spikes * int(self.network_clk // resonator.clk_freq)\n",
    "\n",
    "                neuron_id = ch_id * len(self.map_resonator_to_id) + resonator_id\n",
    "                result[result_index:result_index + len(ts_spikes), 0] = ts_spikes\n",
    "                result[result_index:result_index + len(ts_spikes), 1] = neuron_id\n",
    "                result_index += len(ts_spikes)\n",
    "\n",
    "        return result, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "trial = Trial(f'../datasets/EEG_data_for_Mental_Attention_State_Detection/EEG_spikes_clk/', 3)\n",
    "\n",
    "labels_mapper = {\n",
    "    'drowesed': 0,\n",
    "    'focus': 1,\n",
    "    'unfocus': 2,\n",
    "}\n",
    "train_dataset = EEGMentalSpikesDataset(trials=[trial], minutes=[5, 15, 25], time_sample_s=.05, labels_mapper=labels_mapper)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "val_dataset = EEGMentalSpikesDataset(trials=[trial], minutes=[6, 16, 26], time_sample_s=.05, labels_mapper=labels_mapper)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "0.19999051094055176"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "x, targets = next(iter(train_dataloader))\n",
    "time.time() - st"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 372,  792, 1232, 1660, 2080, 2520, 2956, 3376, 3816, 4236],\n        [ 144,  828, 1600, 2040, 2476, 2912, 3352, 3772, 4200, 4640],\n        [ 324,  744, 1184, 1604, 2024, 2464, 2884, 3304, 3744, 4180],\n        [   4,  432,  872, 1292, 1728, 2168, 2588, 3008, 3428, 3868],\n        [ 368,  788, 1296, 1736, 2164, 2944, 3380, 3820, 4240, 4680],\n        [ 104,  540,  980, 1400, 1840, 2260, 2680, 3120, 3540, 3960],\n        [ 316,  756, 1184, 1612, 2052, 2472, 2912, 3332, 3752, 4192],\n        [ 252,  672, 1092, 1532, 1952, 2372, 2812, 3232, 3652, 4092],\n        [ 412,  832, 1252, 1692, 1848, 2288, 2708, 3128, 3568, 3988],\n        [ 168,  588, 1024, 1464, 1884, 2304, 2724, 3164, 3592, 4012],\n        [ 192,  788, 1576, 1996, 2436, 2856, 3276, 3716, 4136, 4556],\n        [ 376,  816, 1236, 1672, 2112, 2532, 2972, 3392, 3812, 4252],\n        [   8,  448,  868, 1304, 1740, 2180, 2600, 3020, 3440, 3880],\n        [ 216,  656, 1076, 1496, 1936, 2356, 2792, 3212, 3652, 4088],\n        [ 200,  640, 1060, 1500, 1920, 2356, 2796, 3564, 4248, 4932],\n        [  16,  456,  876, 1316, 1752, 2172, 2612, 3032, 3460, 3900],\n        [ 700, 1140, 1568, 2008, 2428, 2760, 3200, 3620, 4216, 4988],\n        [ 392,  812, 1252, 1680, 2120, 2548, 2984, 3424, 3844, 4284],\n        [ 292,  712, 1152, 1572, 1992, 2432, 2588, 3028, 3448, 3868],\n        [ 416,  856, 1276, 1696, 2116, 2536, 2956, 3396, 3816, 4236],\n        [ 328,  748, 1168, 1852, 2448, 3132, 3816, 4420, 5104, 5700],\n        [ 344,  764, 1204, 1624, 2060, 2500, 2936, 3364, 3960, 4644],\n        [ 396,  816, 1256, 1676, 2096, 2536, 2956, 3376, 3812, 4252],\n        [ 144,  652, 1092, 1872, 2292, 2720, 3160, 3316, 3756, 4176],\n        [ 108,  544,  984, 1404, 1840, 2612, 3052, 3472, 3980, 4420],\n        [ 120,  560,  980, 1400, 1996, 2592, 3372, 3792, 4232, 4652],\n        [ 288,  716, 1152, 1592, 2020, 2456, 2876, 3316, 3744, 4164],\n        [ 308,  744, 1164, 1604, 2024, 2444, 2864, 3304, 3724, 4144],\n        [ 268,  708, 1136, 1576, 1996, 2416, 2856, 3276, 3716, 4136],\n        [  84,  504,  932, 1372, 1792, 2232, 2652, 3072, 3512, 3948],\n        [  12,  452,  872, 1300, 1740, 2160, 2580, 3020, 3440, 3860],\n        [ 396,  832, 1252, 1692, 2112, 2532, 2960, 3400, 3828, 4248],\n        [ 428, 1024, 1620, 2216, 2812, 3328, 4012, 4520, 5204, 5992],\n        [ 124,  564,  992, 1432, 1852, 2272, 2712, 3140, 3580, 4000],\n        [  40,  460,  888, 1328, 1748, 2184, 2624, 3044, 3464, 3904],\n        [ 224,  468, 1152, 1748, 2344, 2784, 3204, 3624, 4064, 4484],\n        [ 396,  836, 1256, 1696, 2116, 2624, 3308, 4080, 4764, 5536],\n        [  44,  464, 1060, 1656, 2436, 2768, 3208, 3628, 4048, 4488],\n        [ 208,  648, 1320, 1760, 2188, 2608, 3028, 3468, 3888, 4308],\n        [ 420,  856, 1276, 1716, 2492, 2932, 3352, 3780, 4220, 4640],\n        [  24,  464,  884, 1324, 1744, 2164, 2604, 3024, 3464, 3884],\n        [ 232,  652, 1092, 1512, 1932, 2372, 2792, 3212, 3652, 4072],\n        [   0,  440,  860, 1300, 1728, 2148, 2588, 3008, 3448, 3868],\n        [ 348,  768, 1208, 1636, 2064, 2484, 2924, 3344, 3764, 4204],\n        [ 108,  548,  968, 1388, 1828, 2248, 2668, 3108, 3528, 3948],\n        [ 348,  944, 1628, 2224, 2908, 3504, 3944, 4364, 4784, 5224],\n        [ 320,  756, 1196, 1616, 2036, 2476, 2896, 3316, 3756, 4176],\n        [ 368,  808, 1228, 1824, 2524, 3296, 3980, 4752, 5524, 6208],\n        [ 352,  792, 1212, 1632, 2072, 2492, 2932, 3352, 3772, 4212],\n        [   4,  424,  864, 1292, 1712, 2484, 3168, 3868, 4640, 5080],\n        [ 404,  844, 1264, 1684, 2124, 2544, 2984, 3404, 3844, 4272],\n        [ 140,  560,  980, 1420, 1840, 2280, 2700, 3120, 3560, 3980],\n        [  48,  468,  888, 1328, 1748, 2184, 2604, 3288, 4076, 4496],\n        [ 388, 1072, 1668, 2108, 2528, 3316, 3560, 4156, 4840, 5280],\n        [ 196,  636, 1056, 1476, 1916, 2336, 2756, 3196, 3616, 4036],\n        [ 168,  588, 1028, 1448, 1876, 2316, 2736, 2980, 3420, 3840],\n        [ 176,  964, 1384, 1824, 2252, 2672, 3112, 3532, 3952, 4372],\n        [ 368,  788, 1228, 1648, 2084, 2524, 2944, 3380, 3820, 4256],\n        [ 112,  552,  972, 1392, 1832, 2252, 2680, 3120, 3540, 3960],\n        [ 320,  740, 1180, 1600, 2020, 2460, 2888, 3328, 3748, 4168],\n        [  24,  628, 1312, 2084, 2524, 2680, 3120, 3540, 3960, 4400],\n        [ 144,  564,  984, 1424, 1844, 2264, 2704, 3124, 3544, 3980],\n        [ 220,  640, 1068, 1508, 1928, 2348, 2788, 3208, 3628, 4068],\n        [ 288,  728, 1148, 1568, 1988, 2428, 2848, 3268, 3708, 4144],\n        [ 316,  744, 1172, 1612, 2032, 2452, 2872, 3308, 3748, 4168],\n        [ 148,  568, 1008, 1428, 1868, 2288, 2728, 3148, 3584, 4196],\n        [ 220, 1008, 1448, 1868, 2288, 2728, 3148, 3568, 3988, 4428],\n        [  56,  484,  904, 1344, 1780, 2220, 2640, 3060, 3500, 3928],\n        [ 396,  836, 1264, 1704, 2124, 2544, 2984, 3420, 3860, 4280],\n        [ 232,  652, 1092, 1512, 1932, 2372, 2792, 3212, 3652, 4080],\n        [ 128,  548,  988, 1408, 1828, 2248, 2688, 3108, 3528, 3968],\n        [ 288,  728, 1148, 1588, 2024, 2812, 3144, 3836, 4520, 5292],\n        [ 140,  580, 1000, 1420, 1860, 2280, 2700, 3140, 3560, 4068],\n        [ 364,  784, 1224, 1644, 2064, 2504, 2932, 3352, 3792, 4212],\n        [  68,  848, 1276, 1716, 2136, 2380, 3064, 3660, 4344, 4784],\n        [ 108,  548,  984, 1764, 2184, 2624, 3044, 3480, 3920, 4340],\n        [ 424,  844, 1284, 1704, 2124, 2564, 2984, 3404, 3844, 4264],\n        [ 132,  552,  992, 1420, 1840, 2280, 2708, 3128, 3568, 3988],\n        [ 228,  664, 1084, 1524, 1944, 2364, 2804, 3224, 3644, 4084],\n        [ 352,  792, 1228, 1648, 2088, 2508, 2928, 3348, 3788, 4208],\n        [ 252,  672, 1112, 1532, 1952, 2392, 2820, 3260, 3680, 4276],\n        [ 232,  652, 1092, 1852, 2536, 3220, 3904, 4516, 5288, 5728],\n        [ 160,  596, 1032, 1472, 1892, 2312, 2732, 3152, 3592, 4012],\n        [ 176,  596, 1036, 1456, 1884, 2324, 2752, 3192, 3612, 4032],\n        [ 196,  636,  880, 1320, 2088, 2528, 2948, 3368, 3808, 4228],\n        [  96,  516,  956, 1376, 1796, 2480, 3164, 3848, 4532, 5216],\n        [   8,  436,  864, 1304, 1724, 2160, 2600, 3028, 3448, 3888],\n        [ 156,  576, 1356, 1792, 2036, 2632, 3228, 3824, 4420, 4860],\n        [ 324,  920, 1604, 2200, 2640, 3060, 3480, 3920, 4348, 4768],\n        [ 240,  680, 1100, 1540, 1960, 2388, 2828, 3248, 3688, 4108],\n        [  28,  448,  888, 1308, 1728, 2168, 2596, 3036, 3456, 3876],\n        [ 272,  692, 1112, 1552, 1972, 2392, 2812, 3252, 3672, 4092],\n        [ 152,  932, 1352, 1792, 2212, 2652, 3072, 3492, 3932, 4352],\n        [ 196,  632, 1072, 1492, 1932, 2352, 2792, 3212, 3632, 4072],\n        [  12,  432,  868, 1308, 1744, 2184, 2604, 3024, 3464, 3884],\n        [ 156,  752, 1348, 1944, 2548, 3144, 3748, 4344, 5028, 5536],\n        [ 396,  816, 1252, 1692, 2128, 2548, 2984, 3424, 3844, 4280],\n        [   0,  428,  936, 1620, 2304, 2988, 3672, 4356, 5040, 5724],\n        [ 556, 1240, 2012, 2696, 3468, 4152, 4592, 5012, 5452, 5872],\n        [ 360,  780, 1220, 1640, 2080, 2500, 2940, 3360, 3800, 4220]])"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :10, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((x.shape[0], 25*14))\n",
    "indices = (x[:, :, 0] == 329).nonzero()\n",
    "features = x[indices[:, 0], indices[:, 1], 1]\n",
    "y[indices[:, 0], features] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([  5, 194, 212])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4, x[4, :, 0] == 372, 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5efD9OHkvVU"
   },
   "source": [
    "## Define The Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "I8WkfQIneZat",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6eb4efeb-bc6c-4dc7-d9e4-66ec56617f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.0 GB\n",
      "Max memory allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Define Network\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, network_clk, sample_time_s, num_inputs, beta=.95):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network_clk = network_clk\n",
    "        self.sample_time_s = sample_time_s\n",
    "        self.steps = 5000 #int(self.network_clk * self.sample_time_s)\n",
    "\n",
    "        self.fc1 = nn.Linear(num_inputs, num_inputs * 3)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_inputs * 3, len(labels_mapper))\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def event_ts_to_spikes(self, events_ts, t):\n",
    "        x = np.zeros((events_ts.shape[0], 25*14))\n",
    "        indices = (events_ts[:, :, 0] == t).nonzero()\n",
    "        features = events_ts[indices[:, 0], indices[:, 1], 1]\n",
    "        x[indices[:, 0], features] = 1\n",
    "        return torch.tensor(x, requires_grad=True).float()\n",
    "\n",
    "    def forward(self, events_ts):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif1.init_leaky()\n",
    "        \n",
    "        # Record the final layer\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "        for i in range(self.steps):\n",
    "            spikes = self.event_ts_to_spikes(events_ts, i)\n",
    "            spikes = spikes.to(device)\n",
    "            cur1 = self.fc1(spikes)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            spk_rec.append(spk2)\n",
    "            mem_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk_rec, dim=0), torch.stack(mem_rec, dim=0)\n",
    "        \n",
    "# Load the network onto CUDA if available\n",
    "net = SNN(train_dataset.network_clk, sample_time_s=.05, num_inputs=14*25).to(device)\n",
    "\n",
    "gpu_mem_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "DH_JOR2qgOvu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "52a2c129-7210-4ecb-9aa3-9a9c6deaa83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.0 GB\n",
      "Max memory allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "def train_printer(\n",
    "    data, targets, epoch,\n",
    "    counter, iter_counter,\n",
    "        loss_hist, test_loss_hist, test_data, test_targets):\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "gpu_mem_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Km_5-ekz72U"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "b9ZF1z0XzsZ9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814
    },
    "outputId": "11a82f41-d7c6-4deb-aa6d-b1be76ab977c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc 0.5, val acc 0.5\n",
      "Epoch 0, Iteration 0\n",
      "Train Set Loss: 7616.81\n",
      "Test Set Loss: 5032.32\n",
      "\n",
      "\n",
      "train acc 0.0, val acc 1.0\n",
      "Epoch 0, Iteration 1\n",
      "Train Set Loss: 5414.84\n",
      "Test Set Loss: 6779.80\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[188], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m train_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_dataloader)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Minibatch training loop\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, targets \u001B[38;5;129;01min\u001B[39;00m train_batch:\n\u001B[0;32m     16\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     17\u001B[0m     targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    650\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    651\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 652\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    655\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    656\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    691\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 692\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[103], line 52\u001B[0m, in \u001B[0;36mEEGMentalSpikesDataset.__getitem__\u001B[1;34m(self, id)\u001B[0m\n\u001B[0;32m     49\u001B[0m ticks_in_sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_sample_s \u001B[38;5;241m*\u001B[39m resonator\u001B[38;5;241m.\u001B[39mclk_freq)\n\u001B[0;32m     51\u001B[0m ts_spikes \u001B[38;5;241m=\u001B[39m resonator\u001B[38;5;241m.\u001B[39mevents\n\u001B[1;32m---> 52\u001B[0m ts_spikes \u001B[38;5;241m=\u001B[39m ts_spikes[(\u001B[43mts_spikes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mticks_in_sample\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m&\u001B[39m (ts_spikes \u001B[38;5;241m<\u001B[39m ((sample \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m ticks_in_sample))]\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# make sure all spikes are aligned even though the spikes come from different clocks and different timestamp!\u001B[39;00m\n\u001B[0;32m     55\u001B[0m ts_spikes \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m (sample \u001B[38;5;241m*\u001B[39m ticks_in_sample)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "val_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_dataloader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # targets = F.one_hot(targets, num_classes=len(labels_mapper))\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data)\n",
    "\n",
    "        _, idx = spk_rec.sum(dim=0).max(1)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(net.steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Val set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_data, val_targets = next(iter(val_dataloader))\n",
    "            val_data = val_data.to(device)\n",
    "            val_targets = val_targets.to(device)\n",
    "\n",
    "            # Val set forward pass\n",
    "            val_spk, val_mem = net(val_data)\n",
    "\n",
    "            _, idx = val_spk.sum(dim=0).max(1)\n",
    "            val_acc = np.mean((val_targets == idx).detach().cpu().numpy())\n",
    "\n",
    "            # Val set loss\n",
    "            val_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(net.steps):\n",
    "                val_loss += loss(val_mem[step], val_targets)\n",
    "            val_loss_hist.append(val_loss.item())\n",
    "\n",
    "            # Print train/val loss/accuracy\n",
    "            if counter % 1 == 0:\n",
    "              print(f'train acc {train_acc}, val acc {val_acc}')\n",
    "              train_printer(\n",
    "                  data, targets, epoch,\n",
    "                  counter, iter_counter,\n",
    "                  loss_hist, val_loss_hist,\n",
    "                  val_data, val_targets)\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANN"
   ],
   "metadata": {
    "id": "zSChQREpKCbV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(14, 32, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 3))\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
    "        self.fc1 = nn.Linear(179456, 1024)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.dtype)\n",
    "        x = self.conv1(x.float())\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "cnet = CNN().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnet.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "gpu_mem_state()"
   ],
   "metadata": {
    "id": "hhtgrWTCopta",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ed5a1e0-0076-4d84-b38c-493cf0473d7d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory allocated: 0.6859326362609863 GB\n",
      "Max memory allocated: 0.6859326362609863 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# del data\n",
    "# del targets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_mem_state()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AxsuUleTneA",
    "outputId": "8688ecc6-d773-4231-ccdb-0aec30b913b3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory allocated: 0.6859326362609863 GB\n",
      "Max memory allocated: 0.6859326362609863 GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "# Define the train and validation loops\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for data, target in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = 100. * train_correct / len(train_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in  tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = 100. * val_correct / len(val_loader.dataset)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Train and validate the CNN\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss, train_acc = train(cnet, train_loader, optimizer, loss, device)\n",
    "    val_loss, val_acc = validate(cnet, val_loader, loss, device)\n",
    "    print(f'Epoch {epoch}: Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.2f}%')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "An4-iHRsQSuE",
    "outputId": "c6853dd9-d92f-40f3-f0c8-aa45de8d4f96"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: Train Loss: 0.047621, Train Acc: 32.21%, Val Loss: 0.046404, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2: Train Loss: 0.045774, Train Acc: 34.48%, Val Loss: 0.046393, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3: Train Loss: 0.045769, Train Acc: 34.48%, Val Loss: 0.046397, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4: Train Loss: 0.045768, Train Acc: 34.48%, Val Loss: 0.046395, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: Train Loss: 0.045768, Train Acc: 34.48%, Val Loss: 0.046392, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6: Train Loss: 0.045768, Train Acc: 34.48%, Val Loss: 0.046390, Val Acc: 34.48%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-c08d150d81f3>\u001B[0m in \u001B[0;36m<cell line: 38>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0mn_epochs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_epochs\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m     \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     40\u001B[0m     \u001B[0mval_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Epoch {epoch}: Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.2f}%'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-c08d150d81f3>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, train_loader, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mtrain_correct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Training\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mleave\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1176\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1177\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1178\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1179\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    632\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    676\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    677\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 678\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    679\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    680\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-884cfb72a501>\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, id)\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mdata1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{self.samples_folder}/{fname}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'spikes'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m       \u001B[0mdata2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{self.samples_folder}/{trial}_{start_time_ms+3000}.npz'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'spikes'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m       \u001B[0mdata2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{self.samples_folder}/{trial}_{start_time_ms+2999}.npz'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'spikes'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    241\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmagic\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMAGIC_PREFIX\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m                 \u001B[0mbytes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 243\u001B[0;31m                 return format.read_array(bytes,\n\u001B[0m\u001B[1;32m    244\u001B[0m                                          \u001B[0mallow_pickle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallow_pickle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    245\u001B[0m                                          pickle_kwargs=self.pickle_kwargs)\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\u001B[0m in \u001B[0;36mread_array\u001B[0;34m(fp, allow_pickle, pickle_kwargs)\u001B[0m\n\u001B[1;32m    776\u001B[0m                     \u001B[0mread_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_read_count\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    777\u001B[0m                     \u001B[0mread_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mread_count\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitemsize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 778\u001B[0;31m                     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_read_bytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mread_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"array data\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    779\u001B[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001B[1;32m    780\u001B[0m                                                              count=read_count)\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\u001B[0m in \u001B[0;36m_read_bytes\u001B[0;34m(fp, size, error_template)\u001B[0m\n\u001B[1;32m    905\u001B[0m         \u001B[0;31m# done about that.  note that regular files can't be non-blocking\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    906\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 907\u001B[0;31m             \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    908\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/zipfile.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_offset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mn\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_eof\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 927\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    928\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_readbuffer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/zipfile.py\u001B[0m in \u001B[0;36m_read1\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m   1001\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compress_type\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mZIP_DEFLATED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1002\u001B[0m             \u001B[0mn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMIN_READ_SIZE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1003\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_decompressor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecompress\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1004\u001B[0m             self._eof = (self._decompressor.eof or\n\u001B[1;32m   1005\u001B[0m                          \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compress_left\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(cnet.state_dict(), '\"/content/drive/MyDrive/SNN-Thesis/cnn_trained_model.pth')"
   ],
   "metadata": {
    "id": "8yIeqKAtT7-S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "api_key = '8236F572-BB36-431D-A64C-3A21B2751024'\n",
    "\n",
    "symbol = 'BTC_USDT'.upper().replace('-', '_')\n",
    "trades = []\n",
    "endpoint = f'https://rest.coinapi.io/v1/trades/BINANCEFTS_PERP_{symbol}/history'\n",
    "params = {\n",
    "    'apikey': api_key,\n",
    "    'time_start': '2023-03-21T08:59:54+00:00',\n",
    "    'limit': 100,\n",
    "}\n",
    "response = requests.get(endpoint, params=params, headers={'Accept': 'application/json'})\n"
   ],
   "metadata": {
    "id": "aLxavaeFWIKf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "response"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYbg_gWoCuVj",
    "outputId": "4b31814f-64bf-42e1-9379-08b73bb262f3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Dcfgz2n9CwBL"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
