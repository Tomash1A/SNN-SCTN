{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "try:\n",
    "    from bindsnet.network import Network\n",
    "except:\n",
    "    from bindsnet.network import Network\n",
    "\n",
    "from bindsnet.learning import PostPre\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.nodes import LIFNodes, Input\n",
    "from bindsnet.analysis.plotting import plot_spikes\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class Topographies2SNN(Network):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape: Tuple,\n",
    "                 fc_layers: List[int],\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        fc1_layer = self._add_layer(fc_layers[0], name='fc1_layer')\n",
    "        for band_name in ['Delta','Theta','Alpha','Beta','Gamma']:\n",
    "            layer_name = f'{band_name}-topography'\n",
    "            input_layer = self._add_input_layer(name=layer_name, shape=input_shape)\n",
    "            self._add_connection(input_layer, fc1_layer,\n",
    "                                 layer_name, 'fc1_layer')\n",
    "\n",
    "        prev_layer = fc1_layer\n",
    "        for i, n in enumerate(fc_layers[1:]):\n",
    "            layer = self._add_layer(n, name=f'fc{i+2}_layer')\n",
    "            self._add_connection(prev_layer, layer,\n",
    "                                 f'fc{i+1}_layer', f'fc{i+2}_layer')\n",
    "            prev_layer = layer\n",
    "\n",
    "    def _add_input_layer(self, name, shape):\n",
    "        input_layer = Input(\n",
    "            n=math.prod(shape),\n",
    "            shape=shape,\n",
    "            traces=True,\n",
    "            tc_trace=20.0\n",
    "        )\n",
    "        self.add_layer(input_layer, name=name)\n",
    "        return input_layer\n",
    "\n",
    "    def _add_layer(self, n, name):\n",
    "        layer = LIFNodes(\n",
    "            n=n,\n",
    "            traces=True,\n",
    "            rest=0.0,\n",
    "            thresh=10,\n",
    "        )\n",
    "        self.add_layer(layer, name=name)\n",
    "        return layer\n",
    "\n",
    "    def _add_connection(self, source, target,\n",
    "                        source_name, target_name\n",
    "    ):\n",
    "        w = 0.5 * torch.rand(source.n, target.n)\n",
    "        conn = Connection(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            w=w,\n",
    "            update_rule=PostPre,\n",
    "            norm=78.4,\n",
    "            nu=(1e-4, 1e-2),\n",
    "        )\n",
    "        self.add_connection(conn,\n",
    "                            source=source_name,\n",
    "                            target=target_name)\n",
    "\n",
    "\n",
    "bands = {\n",
    "    'Delta': (.5, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 14),\n",
    "    'Beta': (14, 32),\n",
    "    'Gamma': (32, 62),\n",
    "}\n",
    "\n",
    "def merge_n_shuffle_tensors(*dicts: Dict, label_tensor):\n",
    "    merged_dict = {}\n",
    "\n",
    "    batch_size = list(dicts[0].values())[0].shape[1]\n",
    "    # Generate random permutations for shuffling along axis 1\n",
    "    perm_indices = torch.randperm(3 * batch_size)\n",
    "    label_tensor = label_tensor[perm_indices]\n",
    "\n",
    "    # Loop through the keys in one of the dictionaries (assuming they all have the same keys)\n",
    "    for key in dicts[0].keys():\n",
    "        # Concatenate the tensors along the second dimension (b)\n",
    "        merged_value = torch.cat([d[key] for d in dicts], dim=1)\n",
    "\n",
    "        # Assign the merged tensor to the corresponding key in the merged dictionary\n",
    "        merged_dict[key] = merged_value[:, perm_indices, :, :]\n",
    "    return merged_dict, label_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = DiehlAndCook2015(\n",
    "    n_inpt=5 * 11 * 11,\n",
    "    n_neurons=100,\n",
    "    exc=22.5,\n",
    "    inh=120,\n",
    "    dt=1,\n",
    "    norm=78.4,\n",
    "    nu=(1e-4, 1e-2),\n",
    "    theta_plus=0.05,\n",
    "    inpt_shape=(5, 11, 11),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "output_neurons = 64\n",
    "\n",
    "fc_layers = [121, output_neurons]\n",
    "snn = Topographies2SNN(input_shape=(11, 11),\n",
    "                       fc_layers=fc_layers,\n",
    "                       )\n",
    "ouput_layer_name = f'fc{len(fc_layers)}_layer'\n",
    "output_path_dir = Path('../datasets/EEG_data_for_Mental_Attention_State_Detection/preprocessed_resonators')\n",
    "\n",
    "trial = '3'\n",
    "band_name = 'Delta'\n",
    "minute = 3\n",
    "step = 0\n",
    "# prefer to have batch size that is divided by 3 and its divide the number 645\n",
    "# batch_size = 129\n",
    "batch_size = 30\n",
    "update_step = 1\n",
    "update_interval = batch_size * update_step\n",
    "sim_time = 1000\n",
    "# sim_time = 153600 // 4\n",
    "labeled_inputs = {\n",
    "    key: {\n",
    "        f'{band_name}-topography': torch.load(output_path_dir / trial / band_name / f'{minute + 10*i}.pt')[:sim_time,\n",
    "                                   step*batch_size//3:(step+1)*batch_size//3, :, :]\n",
    "        for band_name in bands.keys()\n",
    "    }\n",
    "    for i, key in enumerate(['focus', 'unfocus', 'drowsed'])\n",
    "}\n",
    "origin_label_tensor = torch.tensor([0] * (batch_size//3) +\n",
    "                                   [1] * (batch_size//3) +\n",
    "                                   [2] * (batch_size//3))\n",
    "\n",
    "spike_record = torch.zeros((update_interval, sim_time, output_neurons))\n",
    "n_classes = 3\n",
    "assignments = -torch.ones(output_neurons)\n",
    "proportions = torch.zeros((output_neurons, n_classes))\n",
    "rates = torch.zeros((output_neurons, n_classes))\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "labels = []\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "spikes = {}\n",
    "for layer in set(snn.layers):\n",
    "    if layer.endswith('topography'):\n",
    "        continue\n",
    "    spikes[layer] = Monitor(\n",
    "        snn.layers[layer], state_vars=[\"s\"], time=sim_time,\n",
    "    )\n",
    "    snn.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [121, 121] doesn't match the broadcast shape [30, 121, 121]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[199], line 62\u001B[0m\n\u001B[0;32m     59\u001B[0m labels\u001B[38;5;241m.\u001B[39mextend(label_tensor\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# Run the network on the input.\u001B[39;00m\n\u001B[1;32m---> 62\u001B[0m \u001B[43msnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msim_time\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m s \u001B[38;5;241m=\u001B[39m spikes[ouput_layer_name]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     64\u001B[0m spike_record[\n\u001B[0;32m     65\u001B[0m             (step \u001B[38;5;241m*\u001B[39m batch_size) \u001B[38;5;241m%\u001B[39m update_interval :\n\u001B[0;32m     66\u001B[0m             (step \u001B[38;5;241m*\u001B[39m batch_size \u001B[38;5;241m%\u001B[39m update_interval) \u001B[38;5;241m+\u001B[39m s\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     67\u001B[0m         ] \u001B[38;5;241m=\u001B[39m s\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\network\\network.py:441\u001B[0m, in \u001B[0;36mNetwork.run\u001B[1;34m(self, inputs, time, one_step, **kwargs)\u001B[0m\n\u001B[0;32m    438\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    439\u001B[0m             kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma_plus\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m A_Plus\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnections[c]\u001B[38;5;241m.\u001B[39mupdate(\n\u001B[0;32m    442\u001B[0m         mask\u001B[38;5;241m=\u001B[39mmasks\u001B[38;5;241m.\u001B[39mget(c, \u001B[38;5;28;01mNone\u001B[39;00m), learning\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearning, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    443\u001B[0m     )\n\u001B[0;32m    445\u001B[0m \u001B[38;5;66;03m# # Get input to all layers.\u001B[39;00m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;66;03m# current_inputs.update(self._get_inputs())\u001B[39;00m\n\u001B[0;32m    447\u001B[0m \n\u001B[0;32m    448\u001B[0m \u001B[38;5;66;03m# Record state variables of interest.\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmonitors:\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\network\\topology.py:240\u001B[0m, in \u001B[0;36mConnection.update\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;66;03m# language=rst\u001B[39;00m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03m    Compute connection's update rule.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 240\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\network\\topology.py:114\u001B[0m, in \u001B[0;36mAbstractConnection.update\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m learning \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m learning:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_rule\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    116\u001B[0m mask \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\learning\\learning.py:399\u001B[0m, in \u001B[0;36mPostPre._connection_update\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    397\u001B[0m     source_s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource\u001B[38;5;241m.\u001B[39ms\u001B[38;5;241m.\u001B[39mview(batch_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m    398\u001B[0m     target_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39mview(batch_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnu[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mw \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction(torch\u001B[38;5;241m.\u001B[39mbmm(source_s, target_x), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m source_s, target_x\n\u001B[0;32m    402\u001B[0m \u001B[38;5;66;03m# Post-synaptic update.\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: output with shape [121, 121] doesn't match the broadcast shape [30, 121, 121]"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for step in range(0, update_step*10 + 1):\n",
    "    if step % update_step == 0 and step > 0:\n",
    "        label_tensor = torch.tensor(labels)\n",
    "\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(\n",
    "            spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "        )\n",
    "        proportion_pred = proportion_weighting(\n",
    "            spikes=spike_record,\n",
    "            assignments=assignments,\n",
    "            proportions=proportions,\n",
    "            n_labels=n_classes,\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "            % (\n",
    "                accuracy[\"all\"][-1],\n",
    "                np.mean(accuracy[\"all\"]),\n",
    "                np.max(accuracy[\"all\"]),\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "            \" (best)\\n\"\n",
    "            % (\n",
    "                accuracy[\"proportion\"][-1],\n",
    "                np.mean(accuracy[\"proportion\"]),\n",
    "                np.max(accuracy[\"proportion\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(\n",
    "            spikes=spike_record,\n",
    "            labels=label_tensor,\n",
    "            n_labels=n_classes,\n",
    "            rates=rates,\n",
    "        )\n",
    "\n",
    "        labels = []\n",
    "\n",
    "    inputs, label_tensor = merge_n_shuffle_tensors(labeled_inputs['focus'], labeled_inputs['unfocus'], labeled_inputs['drowsed'],\n",
    "                                                   label_tensor=origin_label_tensor)\n",
    "    labels.extend(label_tensor.tolist())\n",
    "\n",
    "    # Run the network on the input.\n",
    "    snn.run(inputs=inputs, time=sim_time)\n",
    "    s = spikes[ouput_layer_name].get(\"s\").permute((1, 0, 2))\n",
    "    spike_record[\n",
    "                (step * batch_size) % update_interval :\n",
    "                (step * batch_size % update_interval) + s.size(0)\n",
    "            ] = s\n",
    "    spikes_output = {\n",
    "        monitor_name: monitor.get('s')\n",
    "        for monitor_name, monitor in spikes.items()\n",
    "    }\n",
    "    print({monitor_name: monitor.get('s').sum() for monitor_name, monitor in spikes.items()})\n",
    "    # plot_spikes(spikes_output)\n",
    "    # plt.show()\n",
    "    snn.reset_state_variables()  # Reset state variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 30, 11, 11])"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inputs.values())[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
